{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tree label\n",
      "1490\n",
      "reading tree\n",
      "tree no: 3098\n",
      "loading train set\n",
      "300 296 298 300\n",
      "loading test set\n",
      "74 74 74 74\n",
      "train no: 1194 1194 1194 1194 1194\n",
      "test no: 296 296 296 296 296\n",
      "dim1 for 0: 79 80 79\n",
      "case 0: [0 2] [1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.] [  32   16    3    4    5    1  138    7 2028   48  369  372  278  413\n",
      "    0    0    0    0    0    0    0    0    0    0    0] 3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@object: Twitter\n",
    "@task: Main function of recursive NN (4 classes)\n",
    "@author: majing\n",
    "@structure: Top-Down recursive Neural Networks\n",
    "@variable: Nepoch, lr, obj, fold\n",
    "@time: Jan 24, 2018\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from importlib import reload\n",
    "reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')\n",
    "\n",
    "import TD_RvNN\n",
    "import math\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from evaluate import *\n",
    "#from Util import *\n",
    "\n",
    "obj = \"Twitter15\" # choose dataset, you can choose either \"Twitter15\" or \"Twitter16\"\n",
    "fold = \"2\" # fold index, choose from 0-4\n",
    "tag = \"_u2b\"\n",
    "vocabulary_size = 5000\n",
    "hidden_dim = 100\n",
    "Nclass = 4\n",
    "#Nepoch = 600 #TODO: change later \n",
    "Nepoch = 1\n",
    "lr = 0.005\n",
    "\n",
    "unit=\"TD_RvNN-\"+obj+str(fold)+'-vol.'+str(vocabulary_size)+tag\n",
    "#lossPath = \"../loss/loss-\"+unit+\".txt\"\n",
    "#modelPath = \"../param/param-\"+unit+\".npz\" \n",
    "\n",
    "treePath = '../resource/data.TD_RvNN.vol_'+str(vocabulary_size)+'.txt' \n",
    "\n",
    "trainPath = \"../nfold/RNNtrainSet_\"+obj+str(fold)+\"_tree.txt\" \n",
    "testPath = \"../nfold/RNNtestSet_\"+obj+str(fold)+\"_tree.txt\"\n",
    "labelPath = \"../resource/\"+obj+\"_label_All.txt\"\n",
    "\n",
    "#floss = open(lossPath, 'a+')\n",
    "\n",
    "################################### tools #####################################\n",
    "def str2matrix(Str, MaxL): # str = index:wordfreq index:wordfreq\n",
    "    wordFreq, wordIndex = [], []\n",
    "    l = 0\n",
    "    for pair in Str.split(' '):\n",
    "        wordFreq.append(float(pair.split(':')[1]))\n",
    "        wordIndex.append(int(pair.split(':')[0]))\n",
    "        l += 1\n",
    "    ladd = [ 0 for i in range( MaxL-l ) ]\n",
    "    wordFreq += ladd \n",
    "    wordIndex += ladd \n",
    "    #print MaxL, l, len(Str.split(' ')), len(wordFreq)\n",
    "    #print Str.split(' ')\n",
    "    return wordFreq, wordIndex \n",
    "\n",
    "def loadLabel(label, l1, l2, l3, l4):\n",
    "    labelset_nonR, labelset_f, labelset_t, labelset_u = ['news', 'non-rumor'], ['false'], ['true'], ['unverified']\n",
    "    if label in labelset_nonR:\n",
    "       y_train = [1,0,0,0]\n",
    "       l1 += 1\n",
    "    if label in labelset_f:\n",
    "       y_train = [0,1,0,0] \n",
    "       l2 += 1\n",
    "    if label in labelset_t:\n",
    "       y_train = [0,0,1,0] \n",
    "       l3 += 1 \n",
    "    if label in labelset_u:\n",
    "       y_train = [0,0,0,1] \n",
    "       l4 += 1\n",
    "    return y_train, l1,l2,l3,l4\n",
    "\n",
    "def constructTree(tree):\n",
    "    ## tree: {index1:{'parent':, 'maxL':, 'vec':}\n",
    "    ## 1. ini tree node\n",
    "    index2node = {}\n",
    "    for i in tree:\n",
    "        node = TD_RvNN.Node_tweet(idx=i)\n",
    "        index2node[i] = node\n",
    "    ## 2. construct tree\n",
    "    for j in tree:\n",
    "        indexC = j \n",
    "        indexP = tree[j]['parent']\n",
    "        nodeC = index2node[indexC]\n",
    "        wordFreq, wordIndex = str2matrix( tree[j]['vec'], tree[j]['maxL'] )\n",
    "        #print tree[j]['maxL']\n",
    "        nodeC.index = wordIndex\n",
    "        nodeC.word = wordFreq\n",
    "        #nodeC.time = tree[j]['post_t']\n",
    "        ## not root node ## \n",
    "        if not indexP == 'None':\n",
    "           nodeP = index2node[int(indexP)]\n",
    "           nodeC.parent = nodeP\n",
    "           nodeP.children.append(nodeC)\n",
    "        ## root node ##\n",
    "        else:\n",
    "           root = nodeC\n",
    "    ## 3. convert tree to DNN input    \n",
    "    parent_num = tree[j]['parent_num'] \n",
    "    ini_x, ini_index = str2matrix( \"0:0\", tree[j]['maxL'] )\n",
    "    #x_word, x_index, tree = tree_gru_u2b.gen_nn_inputs(root, ini_x, ini_index) \n",
    "    x_word, x_index, tree = TD_RvNN.gen_nn_inputs(root, ini_x) \n",
    "    return x_word, x_index, tree, parent_num       \n",
    "               \n",
    "################################# loas data ###################################\n",
    "def loadData():\n",
    "    print(\"loading tree label\",)\n",
    "    labelDic = {}\n",
    "    for line in open(labelPath):\n",
    "        line = line.rstrip()\n",
    "        label, eid = line.split('\\t')[0], line.split('\\t')[2]\n",
    "        labelDic[eid] = label.lower()   \n",
    "    print(len(labelDic))\n",
    "    \n",
    "    print(\"reading tree\",) ## X\n",
    "    treeDic = {}\n",
    "    for line in open(treePath):\n",
    "        line = line.rstrip()\n",
    "        eid, indexP, indexC = line.split('\\t')[0], line.split('\\t')[1], int(line.split('\\t')[2])\n",
    "        parent_num, maxL = int(line.split('\\t')[3]), int(line.split('\\t')[4])  \n",
    "        Vec =  line.split('\\t')[5] \n",
    "        #if not treeDic.has_key(eid):\n",
    "        if eid not in treeDic:\n",
    "           treeDic[eid] = {}\n",
    "        treeDic[eid][indexC] = {'parent':indexP, 'parent_num':parent_num, 'maxL':maxL, 'vec':Vec}   \n",
    "    print('tree no:', len(treeDic))\n",
    "    \n",
    "    print(\"loading train set\",)\n",
    "    tree_train, word_train, index_train, y_train, parent_num_train, c = [], [], [], [], [], 0\n",
    "    l1,l2,l3,l4 = 0,0,0,0\n",
    "    for eid in open(trainPath):\n",
    "        #if c > 8: break\n",
    "        eid = eid.rstrip()\n",
    "        #if not labelDic.has_key(eid): continue\n",
    "        #if not treeDic.has_key(eid): continue \n",
    "        if eid not in labelDic: continue\n",
    "        if eid not in treeDic: continue\n",
    "        if len(treeDic[eid]) <= 0: \n",
    "           #print labelDic[eid]\n",
    "           continue\n",
    "        ## 1. load label\n",
    "        label = labelDic[eid]\n",
    "        y, l1,l2,l3,l4 = loadLabel(label, l1, l2, l3, l4)\n",
    "        y_train.append(y)\n",
    "        ## 2. construct tree\n",
    "        #print eid\n",
    "        x_word, x_index, tree, parent_num = constructTree(treeDic[eid])\n",
    "        tree_train.append(tree)\n",
    "        word_train.append(x_word)\n",
    "        index_train.append(x_index)\n",
    "        parent_num_train.append(parent_num)\n",
    "        #print treeDic[eid]\n",
    "        #print tree, child_num\n",
    "        #exit(0)\n",
    "        c += 1\n",
    "    print(l1,l2,l3,l4)\n",
    "    \n",
    "    print(\"loading test set\",)\n",
    "    tree_test, word_test, index_test, parent_num_test, y_test, c = [], [], [], [], [], 0\n",
    "    l1,l2,l3,l4 = 0,0,0,0\n",
    "    for eid in open(testPath):\n",
    "        #if c > 4: break\n",
    "        eid = eid.rstrip()\n",
    "        #if not labelDic.has_key(eid): continue\n",
    "        #if not treeDic.has_key(eid): continue \n",
    "        if eid not in labelDic: continue\n",
    "        if eid not in treeDic: continue\n",
    "        if len(treeDic[eid]) <= 0: \n",
    "           #print labelDic[eid] \n",
    "           continue        \n",
    "        ## 1. load label        \n",
    "        label = labelDic[eid]\n",
    "        y, l1,l2,l3,l4 = loadLabel(label, l1, l2, l3, l4)\n",
    "        y_test.append(y)\n",
    "        ## 2. construct tree\n",
    "        x_word, x_index, tree, parent_num = constructTree(treeDic[eid])\n",
    "        tree_test.append(tree)\n",
    "        word_test.append(x_word)  \n",
    "        index_test.append(x_index) \n",
    "        parent_num_test.append(parent_num)\n",
    "        c += 1\n",
    "    print(l1,l2,l3,l4)\n",
    "    print(\"train no:\", len(tree_train), len(word_train), len(index_train),len(parent_num_train), len(y_train))\n",
    "    print(\"test no:\", len(tree_test), len(word_test), len(index_test), len(parent_num_test), len(y_test))\n",
    "    print(\"dim1 for 0:\", len(tree_train[0]), len(word_train[0]), len(index_train[0]))\n",
    "    print(\"case 0:\", tree_train[0][0], word_train[0][0], index_train[0][0], parent_num_train[0])\n",
    "    #print index_train[0]\n",
    "    #print word_train[0]\n",
    "    #print tree_train[0]    \n",
    "    #exit(0)\n",
    "    return tree_train, word_train, index_train, parent_num_train, y_train, tree_test, word_test, index_test, parent_num_test, y_test\n",
    "\n",
    "##################################### MAIN ####################################        \n",
    "## 1. load tree & word & index & label\n",
    "tree_train, word_train, index_train, parent_num_train, y_train, tree_test, word_test, index_test, parent_num_test, y_test = loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Documents\\Uni\\Last Exams To Master\\Forschungspraktikum Online Polarization\\Programming\\polpol-rumour-sequences-RvNN-Experiments\\Rumor_RvNN-master\\model\\TD_RvNN.py:231: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  return T.nnet.softmax( self.W_out.dot(final_state)+ self.b_out )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive model established, 0.5946231921513875\n"
     ]
    }
   ],
   "source": [
    "## 2. ini RNN model\n",
    "t0 = time.time()\n",
    "model = TD_RvNN.RvNN(vocabulary_size, hidden_dim, Nclass)\n",
    "t1 = time.time()\n",
    "print('Recursive model established,', (t1-t0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TD_RvNN.RvNN.create_recursive_unit.<locals>.unit(word, index, parent_h)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recursive_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = T.iscalar(\"k\")\n",
    "A = T.vector(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, updates = theano.scan(fn=lambda prior_result, A: prior_result * A,\n",
    "                              outputs_info=T.ones_like(A),\n",
    "                              non_sequences=A,\n",
    "                              n_steps=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subtensor{int64::}.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = result[-1]\n",
    "power = theano.function(inputs=[A,k], outputs=final_result, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000000e+00, 1.000000e+00, 1.024000e+03, 5.904900e+04,\n",
       "       1.048576e+06], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power(range(5),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.init_vector([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ini_unit(x):\n",
    "    return theano.shared(model.init_vector([model.hidden_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_node_h, _ = theano.scan(fn = ini_unit, sequences = [model.x_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "for{cpu,scan_fn}.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_node_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subtensor{int32::}.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tree_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
